\documentclass[a4paper, 11pt]{article}

\usepackage[spanish]{babel} % Idioma
\usepackage[utf8]{inputenc} % Codificación
\usepackage[T1]{fontenc} % Codificación
\usepackage{adjustbox} % Tamaño de tablas
\usepackage{float} % Posicionamiento de figure
\usepackage[vmargin=2cm,hmargin=2cm]{geometry} % Márgenes
\usepackage{graphicx} % Imágenes
\usepackage{hyperref} % Enlaces
\graphicspath{{img/}} % Las imágenes están en la carpeta img
\usepackage{accents} % Cosas de Windows
\usepackage{framed} % Frames

\newcommand{\spec}[5]{
\bgroup
\def\arraystretch{1.2}
\begin{tabular}{|l|}
\hline
PC de \textbf{#1}:\\
%Hardware y SO empleado:\\
CPU: #2 @#3 GHz\\RAM: #4 GB \hspace{0.8cm} SO: #5 \\
\hline
\end{tabular}
\egroup
\vspace*{0.2cm}
}

\title{\Huge \textbf{Práctica 1}}

\author{\textbf{Pablo Baeyens Fernández} \\ \textbf{Antonio Checa Molina} \\
\textbf{Iñaki Madinabeitia Cabrera} \\  \textbf{José Manuel Muñoz Fuentes} \\
\textbf{Darío Sierra Martínez} \\ }
\date{Algorítmica}



\begin{document}

\maketitle
\tableofcontents

\newpage
\section{Ejercicio 1}
En el ejercicio 1 se nos pide hallar la eficiencia empírica de los algoritmos
presentados en la sesión. Para ello hemos modificado los códigos de los programas
para que tengan como salida el tamaño que se les pasó como argumento junto al tiempo
que han tardado en realizar la tarea del respectivo algoritmo.
Usando la biblioteca \textit{chrono} y la estructura que se menciona en la
sesión se consiguen medir los tiempos de los programas de forma precisa. \\

Una vez hecho esto, se elaboró un script de bash para automatizar la ejecución de
cada algoritmo con varios tamaños y recoger todas las salidas en un archivo para
luego poder usar esos datos. El script es el siguiente:


\begin{framed}

	\# !/bin/bash

	\# Uso: nombredelejecutable inicial salto final

	\# Ejemplo: fibonacci 10 5 80 ejecuta fibonacci 10, fibonacci 15, ..., fibonacci 80

	\# Salida: nombredelejecutable.dat
	\vspace{0.3cm}

	$>$ \$(basename \$1 .exe).dat

	for i in \$(seq \$2 \$3 \$4); do

	\hspace{0.4cm}./\$1 \$i $>>$ \$(basename \$1 .exe).dat

	done

\end{framed}

Las tablas generadas con este proceso se presentan a continuación, habiendo una tabla
para cada orden de eficiencia y una última tabla que reúne los tiempos de todos los
algoritmos de ordenación. \\

Todos los tiempos que se muestran en las tablas están en segundos, mientras que
\textit{Tamaño} menciona el tamaño total de la muestra con la que se obtuvo cada
tiempo de ejecución: en los algoritmos de ordenación hace referencia a la
capacidad del vector que se ordenaba, mientras que en Fibonacci o Hanói hace
referencia a las iteraciones totales del programa. \\

Cada miembro del grupo ha ejecutado el script en un computador con las siguientes prestaciones:

\noindent
\spec{Antonio}{\href{http://ark.intel.com/products/78930}{Intel\textregistered\ Core\texttrademark\ i7-4710HQ}}{2.50}{8}{Mint 17.3 64 bits}
\spec{Darío}{Intel® Core™ i7-4700HQ}{2.40}{$12$}{Ubuntu 14.04 64-bit} \\
\spec{Iñaki}{\href{http://ark.intel.com/products/81015}{Intel\textregistered\ Core\texttrademark\ i7-4510U}}{2.00}{8}{Mint 17.3 64 bits}
\spec{José Manuel}{\href{http://ark.intel.com/es-es/products/75459/}{Intel\textregistered\ Core\texttrademark\ i5-4200U}}{1.60}{4}{Windows 8.1 64 bits} \\
\spec{Pablo}{\href{http://ark.intel.com/es-es/products/76090/}{Intel\textregistered\ Core\texttrademark\ i7-4760HQ}}{2.10}{7.7}{Ubuntu 15.10 64 bits}

Debido al tamaño de las tablas (ya que cada una debía tener al menos 25 entradas),
cada tabla se muestra en una página. \\

Cabe destacar que la diferencia entre algoritmos de ordenación de un orden y de
otro resulta tan pronunciada que los algoritmos de orden $n \cdot \log (n)$ se
han ejecutado una segunda vez con un rango de valores en el que obtienen tiempos
de ejecución minúsculos, muchos órdenes de magnitud por debajo del obtenido por
los otros algoritmos de ordenación. En la tabla en la que se presentan se usan
tamaños mucho mayores, mientras que en la tabla comparativa de algoritmos de
ordenación toman estos mismos valores.

\subsection{Tabla del algoritmo de burbuja}
\input{tablas/burbuja_tabla}

\subsection{Tabla del algoritmo de selección}
\input{tablas/seleccion_tabla}

\subsection{Tabla del algoritmo de inserción}
\input{tablas/insercion_tabla}

\newpage
\subsection{Tabla de los algoritmos cuadráticos}

\noindent Incluimos una tabla comparando los datos de una sóla persona para los algoritmos de orden cuadrático: \\

\begin{tabular}{|l|l|l|l|}
	\hline
	Tamaño &Tiempo de Burbuja &Tiempo de  Inserción &Tiempo de  Selección \\
	\hline
	\hline
	2000 & 0,0141 & 0,005 & 0,0057 \\
	\hline
	4000 & 0,0516 & 0,0211 & 0,023 \\
	\hline
	6000 & 0,1138 & 0,0423 & 0,0485 \\
	\hline
	8000 & 0,203 & 0,0749 & 0,0853 \\
	\hline
	10000 & 0,3178 & 0,1194 & 0,1335 \\
	\hline
	12000 & 0,4675 & 0,1719 & 0,1922 \\
	\hline
	14000 & 0,6378 & 0,2302 & 0,2608 \\
	\hline
	16000 & 0,8319 & 0,3068 & 0,3446 \\
	\hline
	18000 & 1,0515 & 0,3948 & 0,4365 \\
	\hline
	20000 & 1,2976 & 0,4715 & 0,5323 \\
	\hline
	22000 & 1,5667 & 0,5756 & 0,6479 \\
	\hline
	24000 & 1,8566 & 0,6691 & 0,7654 \\
	\hline
	26000 & 2,1866 & 0,8164 & 0,9028 \\
	\hline
	28000 & 2,5267 & 0,9151 & 1,0435 \\
	\hline
	30000 & 2,9087 & 1,0581 & 1,2003 \\
	\hline
	32000 & 3,3202 & 1,1995 & 1,3639 \\
	\hline
	34000 & 3,7281 & 1,3595 & 1,5385 \\
	\hline
	36000 & 4,1982 & 1,5143 & 1,723 \\
	\hline
	38000 & 4,6725 & 1,684 & 1,9174 \\
	\hline
	40000 & 5,1504 & 1,8823 & 2,1246 \\
	\hline
	42000 & 5,6988 & 2,0988 & 2,3405 \\
	\hline
	44000 & 6,2511 & 2,2693 & 2,5674 \\
	\hline
	46000 & 6,8294 & 2,4624 & 2,8047 \\
	\hline
	48000 & 7,4305 & 2,6661 & 3,054 \\
	\hline
	50000 & 8,0857 & 2,9284 & 3,3125 \\
	\hline
\end{tabular}

\subsection{Tabla del algoritmo Heapsort}
\input{tablas/heapsort_tabla}
\subsection{Tabla del algoritmo Mergesort}
\input{tablas/mergesort_tabla}
\subsection{Tabla del algoritmo Quicksort}
\input{tablas/quicksort_tabla}

\newpage
\subsection{Tabla de los algoritmos $n\cdot \log(n)$}

\noindent Incluimos una tabla comparando los datos de una sóla persona para los algoritmos de orden $n\cdot \log(n)$: \\

\begin{tabular}{|l|l|l|l|}
	\hline
	Tamaño & Tiempo de Heapsort & Tiempo de Mergesort & Tiempo de Quicksort \\
	\hline
	\hline
	1000000	&0,158862&	0,25279&	0,245436\\
	\hline
	2000000	&0,333955&	0,55784	&0,508929\\
	\hline
	3000000	&0,512390&	0,92310	&0,883956\\
	\hline
	4000000	&0,689444&	1,26719	&1,068840\\
	\hline
	5000000	&0,875720&	1,66226	&1,422010\\
	\hline
	6000000	&1,063160&	2,06275	&1,804380\\
	\hline
	7000000	&1,254210&	2,46109	&1,880770\\
	\hline
	8000000	&1,448250&	2,89135	&2,214050\\
	\hline
	9000000	&1,636350&	3,30651	&2,563270\\
	\hline
	10000000	&1,802540&	3,69426	&2,943020\\
	\hline
	11000000	&2,013440&	4,14343	&3,320140\\
	\hline
	12000000	&2,211360&	4,60380	&3,736370\\
	\hline
	13000000	&2,399370&	5,06756	&4,035230\\
	\hline
	14000000	&2,589330&	5,51359	&3,893640\\
	\hline
	15000000	&2,786440&	5,96415	&4,248670\\
	\hline
	16000000	&2,984850&	6,40422	&4,579140\\
	\hline
	17000000	&3,174740&	6,93151	&4,953660\\
	\hline
	18000000	&3,358080&	7,39067	&5,305020\\
	\hline
	19000000	&3,563030&	7,85371	&5,679610\\
	\hline
	20000000	&3,803150&	8,35113	&6,070570\\
	\hline
	21000000	&3,950770&	8,85375	&6,459050\\
	\hline
	22000000	&4,171410&	9,26481	&6,862640\\
	\hline
	23000000	&4,371020&	9,70679	&7,275080\\
	\hline
	24000000	&4,558990&	10,26190	&7,763610\\
	\hline
	25000000	&4,774830&	10,71420	&8,117880\\
	\hline
\end{tabular}

\subsection{Tabla del algoritmo cúbico (Floyd)}
   \input{tablas/floyd_tabla}

\subsection{Tabla del algoritmo de Fibonacci $(O(\varphi^n))$}
   \input{tablas/fibonacci_tabla}

\subsection{Tabla del algoritmo de Hanoi ($O(2^n)$)}
   \input{tablas/hanoi_tabla}

\subsection{Tabla de los algoritmos de ordenación}

\begin{tabular}{|l|l|l|l|l|l|l|}
	\hline
	Tamaño	&Burbuja&	Inserción&	Selección&	Heapsort&	Mergesort&	Quicksort\\
	\hline
	\hline
	2000&	0,014089400&	0,00501	&0,005698&	0,000235&	0,000272&	0,000255\\
	\hline
	4000&	0,051553600&	0,02113	&0,022951&	0,000509&	0,000580&	0,000381\\
	\hline
	6000&	0,113751000&	0,04231&	0,048492&	0,000883&	0,001106&	0,000627\\
	\hline
	8000&	0,202951000&	0,07491&	0,085303&	0,001128&	0,001366&	0,000811\\
	\hline
	10000&	0,317834000&	0,11939&	0,133457&	0,001417&	0,001760&	0,001152\\
	\hline
	12000&	0,467509000&	0,17190&	0,192178&	0,001813&	0,002363&	0,001354\\
	\hline
	14000&	0,637843000&	0,23016&	0,260748&	0,002180&	0,002288&	0,001517\\
	\hline
	16000&	0,831875000&	0,30682&	0,344565&	0,002435&	0,002648&	0,001768\\
	\hline
	18000&	1,051490000&	0,39484&	0,436515&	0,002733&	0,003157&	0,001986\\
	\hline
	20000&	1,297600000&	0,47146&	0,532265&	0,003284&	0,003823&	0,002305\\
	\hline
	22000&	1,566720000&	0,57562&	0,647896&	0,003487&	0,004252&	0,002436\\
	\hline
	24000&	1,856610000&	0,66907&	0,765415&	0,003741&	0,004980&	0,002720\\
	\hline
	26000&	2,186600000&	0,81644&	0,902801&	0,004212&	0,004381&	0,002916\\
	\hline
	28000&	2,526680000&	0,91512&	1,043460&	0,004471&	0,004894&	0,003335\\
	\hline
	30000&	2,908670000&	1,05814&	1,200250&	0,004781&	0,005159&	0,003443\\
	\hline
	32000&	3,320190000&	1,19949&	1,363910&	0,005306&	0,005530&	0,003685\\
	\hline
	34000&	3,728090000&	1,35952&	1,538500&	0,005509&	0,006219&	0,003967\\
	\hline
	36000&	4,198150000&	1,51431&	1,723020&	0,005901&	0,006601&	0,004178\\
	\hline
	38000&	4,672490000&	1,68403&	1,917410&	0,006102&	0,007015&	0,004356\\
	\hline
	40000&	5,150410000&	1,88228&	2,124580&	0,006620&	0,007535&	0,004715\\
	\hline
	42000&	5,698770000&	2,09879&	2,340510&	0,006936&	0,008117&	0,004858\\
	\hline
	44000&	6,251140000&	2,26926&	2,567410&	0,007331&	0,009466&	0,005189\\
	\hline
	46000&	6,829350000&	2,46238&	2,804650&	0,007502&	0,009306&	0,005421\\
	\hline
	48000&	7,430450000&	2,66613&	3,053950&	0,007841&	0,009883&	0,005697\\
	\hline
	50000&	8,085720000&	2,92835&	3,312500&	0,008407&	0,010657&	0,005931\\
	\hline
\end{tabular}

\newpage
\section{Ejercicio 2}

En el ejercicio 2 se pide realizar las gráficas de los algoritmos, que hemos
realizado metiendo en \textit{gnuplot} los datos mostrados en las tablas anteriores,
con los siguientes resultados:

\subsection{Gráfica de los algoritmos cuadráticos}
\begin{figure}[h] \includegraphics[width=14cm]{comparativa_cuadraticos_g} \centering
	\caption{Algoritmos cuadráticos} \end{figure}

El algoritmo de la burbuja requiere más del doble de tiempo que cualquiera de los otros dos, que se encuentran casi igualados, teniendo un menor tiempo el de inserción. Probablemente este menor tiempo sea el motivo de que en \textit{quicksort} y \textit{mergesort} se use el algoritmo de inserción para subvectores pequeños.

\begin{figure}[H] \includegraphics[width=15cm]{burbuja_todos_g} \centering
      \caption{Algoritmo de burbuja} \end{figure}

\begin{figure}[H] \includegraphics[width=15cm]{seleccion_todos_g} \centering
      \caption{Algoritmo de selección} \end{figure}

\begin{figure}[H] \includegraphics[width=15cm]{insercion_todos_g} \centering
      \caption{Algoritmo de inserción} \end{figure}

\newpage
\subsection{Gráfica de los algoritmos $n\cdot log(n)$ }
\begin{figure}[h] \includegraphics[width=14cm]{comparativa_logaritmicos_g} \centering
	\caption{Algoritmos  $n\cdot log(n)$} \end{figure}

En el algoritmo \textit{mergesort} se aprecian pequeños escalones. Probablemente en cada escalón se incrementa el número de llamadas recursivas, de forma que el tamaño de los subvectores para los que se llama a la función de ordenado por selección (que actúa para tamaños de entrada pequeños) es menor. \\
El algoritmo \textit{quicksort} también usa el algoritmo de inserción por debajo de cierto umbral, pero usa un umbral más pequeño. Esto puede ser la causa de que no presente los escalones.

\begin{figure}[h] \includegraphics[width=15cm]{mergesort_todos_g} \centering
   \caption{Algoritmo Mergesort} \end{figure}

Aquí se observa que los escalones aparecen en todas las ejecuciones en distintas
máquinas.

\begin{figure}[H] \includegraphics[width=15cm]{quicksort_todos_g} \centering
   \caption{Algoritmo Quicksort} \end{figure}

\begin{figure}[H] \includegraphics[width=15cm]{heapsort_todos_g} \centering
   \caption{Algoritmo Heapsort} \end{figure}

\newpage

\subsection{Gráfica del algoritmo de Floyd (cúbico)}
\begin{figure}[H] \includegraphics[width=16cm]{floyd_todos_g} \centering
	\caption{Algoritmo de Floyd (cúbico)} \end{figure}

\subsection{Gráfica del algoritmo de Fibonacci $(O(\varphi^n))$}
\begin{figure}[H] \includegraphics[width=16cm]{fibonacci_todos_g} \centering
	\caption{Algoritmo de Fibonacci} \end{figure}

\subsection{Gráfica del algoritmo de Hanoi ($O(2^n)$)}
\begin{figure}[H] \includegraphics[width=16cm]{hanoi_todos_g} \centering
	\caption{Algoritmo de Hanoi} \end{figure}

\subsection{Gráfica de los algoritmos de ordenación}
\begin{figure}[h] \includegraphics[width=16cm]{comparativa_global_g} \centering
	\caption{Algoritmos de ordenación} \end{figure}

La diferencia en el tiempo de ejecución de los algoritmos de un orden de eficiencia y de otro provoca que los tiempos de los algoritmos de orden de eficiencia $n \cdot \log (n)$ se muestren como una línea horizontal.

\newpage
\section{Ejercicio 3}

En las siguientes tablas incluimos el ajuste de los datos obtenidos por cada uno
de los integrantes del grupo con una función representativa de su orden de eficiencia. Indicamos también el coeficiente de correlación lineal ($r$) entre
los datos reales y la función obtenida entre paréntesis junto a la función en las tablas con más de un algoritmo y en su propia columna en el resto.

\subsection{Eficiencia híbrida de los algoritmos cuadráticos}

\noindent\adjustbox{max width=\textwidth}{%
	\begin{tabular}{|l|l|}
		\hline
		Persona & Burbuja \\
		\hline
		
		Antonio & $3.67\cdot 10^{-9}n^2 -3.02\cdot 10^{-5}n + 0.189$ ($0.99$) \\
		\hline
		Darío &$89\cdot10^{-3} -1.62\cdot10^{-5}\cdot n +3\cdot10^{-9}\cdot n^2$ $ (0.99)$ \\
		
		\hline
		José Manuel & $3.85\cdot 10^{-9}n^2 - 7.88\cdot 10^{-6}n + 0.013$ ($0.99$) \\
		\hline
		Pablo & $3\cdot 10^{-9}n^2 -6\cdot 10^{-6}n + 0,015$ ($0.99$) \\
		\hline
		Iñaki & $3.23\cdot 10^{-9}n^2 +1.36\cdot 10^{-7}n -2.52\cdot 10^{-5}$ ($0.99$)\\
		\hline
	\end{tabular}
}

\noindent\adjustbox{max width=\textwidth}{%
	\begin{tabular}{|l|l|}
		\hline
		Persona &Inserción \\
		\hline
		
		Antonio &  $1.21\cdot 10^{-9}n^2 -5.77\cdot 10^{-6}n + 0,003$ ($0.99$)  \\
		\hline
		Darío &$89 \cdot 10^{-3}+-1.62\cdot10^{-5} \cdot n +1.68\cdot 10^{-9}\cdot n^2$ $ (0.99)$ \\
		
		\hline
		José Manuel  & $1.32\cdot 10^{-9}n^2 + 4.95\cdot 10^{-7}n - 0.0024$ ($0.99$) \\
		\hline
		Pablo & $10^{-9}n^2 + 4\cdot 10^{-7}n + 0,002$ ($0.99$) \\
		\hline
		Iñaki & $1.18\cdot 10^{-9}n^2 +1.36 \cdot 10^{-7}n -2.5\cdot 10^{-5}$ ($0.99$)\\
		\hline
	\end{tabular}
}

\noindent\adjustbox{max width=\textwidth}{%
	\begin{tabular}{|l|l|}
		\hline
		Persona & Selección \\
		\hline
		
		Antonio &  $1.459 \cdot 10^{-9}n^2 -5.7\cdot 10^{-6}n + 0,002$ ($1$) \\
		\hline
		Darío &$89\cdot 10^{-3}-1.616\cdot 10^{-5}\cdot n +1.59 \cdot 10^{-9} \cdot n^2$ $(0.99)$ \\
		
		\hline
		José Manuel & $1.59\cdot 10^{-9}n^2 + 2.93 \cdot 10^{-7} n - 0.0022$ $(0.99)$ \\
		\hline
		Pablo & $10^{-9}n^2 -2\cdot 10^{-7}n + 0,004$ ($1$) \\
		\hline
		Iñaki & $1.31\cdot 10^{-9}n^2 +5.81\cdot 10^{-7} -0.002$ ($0.99$)\\
		\hline
	\end{tabular}
}


\subsection{Eficiencia híbrida de los algoritmos $n \cdot \log(n)$}

\noindent\adjustbox{max width=\textwidth}{
\begin{tabular}{|l|l|l|l|}
	\hline
	Persona & Heapsort & Mergesort & Quicksort \\
	\hline

	Antonio & $2.72 \cdot 10^{-8}n\log(n) -0.55$ ($0.999$)  & $1.918 \cdot 10^{-8} n \log(n) - 0.305 $ ($0.996$)& $1.06 \cdot 10^{-8}n\log(n) -0.083 $ ($0.999$)\\
	\hline
	Darío & $2.56\cdot 10^{-8} n\log(n) -0.005$ $(0.99) $&$3.03\cdot 10^{-8}n\log(x) -0.004$ $(0.99)$&$1.46\cdot 10^{-8}\cdot n\log(n) -0.005$ $(0.99)$ \\
	
	\hline
	José Manuel & $3.13\cdot 10^{-8}n\log(n) - 0.37$ ($0.99$) & $2.29 \cdot 10^{-8}n\log(n) - 0.08$ ($0.99$) & $1.42 \cdot 10^{-8}n\log(n) + 0.02$ ($0.99$)\\
	\hline
	Pablo & $1.8 \cdot 10^{-8}n\log(n) -1.9\cdot 10^{-7}$ ($0.995$)  & $2 \cdot 10^{-8} n \log(n) - 1.9\cdot 10^{-7}$ ($0.997$)& $1.3 \cdot 10^{-8}n\log(n) -1.9\cdot 10^{-7}$ ($0.999$)\\
	\hline
	Iñaki & $2.46\cdot 10^{-8}n\log(n) +1.36\cdot 10^{-7}$ ($0.99$)
	& $1.48\cdot 10^{-8}n\log(n) +1$ ($0.99$)
	& $1.12\cdot 10^{-8}n\log(n) +1.36\cdot 10^{-7}$ ($0.99$)\\
	\hline

\end{tabular}
}

\subsection{Eficiencia híbrida del algoritmo de Floyd}
\noindent\adjustbox{max width=\textwidth}{
\begin{tabular}{|l|l|l|}
	\hline
	Persona & Eficiencia híbrida de Floyd & $r$ \\
	\hline
	Antonio & $ 6 \cdot 10^{-9}n^3 -7.9 \cdot 10^{-7}n^2 -2.17 \cdot 10^{-4}n +0.012$ & $0.999$ \\
	\hline
	Darío & $6.98\cdot 10^{-9} \cdot n^3 -7.66\cdot 10^{-7}\cdot n^2 +0.0002\cdot n -0.005$ & $0.999$ \\
	
	\hline
	José Manuel & $ 6.88 \cdot 10^{-9}n^3 + 2.89 \cdot 10^{-7}n^2 -4.44 \cdot 10^{-5}n +0.001$ & $0.999$ \\
	\hline
	Pablo & $ 5.1 \cdot 10^{-9}n^3 + 3.8 \cdot 10^{-7}n^2 -8.3 \cdot 10^{-5}n +0.005$ & $1$ \\
	\hline
	Iñaki & $5.76\cdot 10^{-9}n^3 +1.36\cdot 10^{-7}n^2 -2.52\cdot 10^{-5}n +0.002$ & $0.999$\\
	\hline

\end{tabular}
}

\subsection{Eficiencia híbrida del algoritmo de Fibonacci}
\noindent\adjustbox{max width=\textwidth}{
\begin{tabular}{|l|l|l|}

	\hline
	Persona & Eficiencia híbrida de Fibonacci & $r$ \\
	\hline

	Antonio & $3.81 \cdot 10^{-9} \varphi^n +7.21\cdot 10^{-7}$ & $0.999$\\
	\hline
	Darío & $0.002\cdot\varphi^n -0.004$ &$0.999$\\
	
	\hline
	José Manuel & $3.81 \cdot 10^{-9} \varphi^n +9.68\cdot 10^{-7}$ & $0.999$\\
	\hline
	Pablo & $6.4 \cdot 10^{-9} \varphi^n -1.8\cdot 10^{-8}$ & $0.997$\\
	\hline
	Iñaki & $4.29\cdot 10^{-9} \varphi^n +5.6\cdot 10^{-6}$ & $0.995$\\
	\hline
\end{tabular}}

\subsection{Eficiencia híbrida del algoritmo de Hanoi}
\noindent\adjustbox{max width=\textwidth}{
\begin{tabular}{|l|l|l|}
	\hline
	Persona & Eficiencia híbrida de Hanoi & $r$ \\
	\hline

	Antonio & $5.69 \cdot 10^{-9} 2^n + 1.1 \cdot 10^{-4}$ & $1$\\
	\hline
	Darío & $6.38\cdot 10^{-9}\cdot 2^n -0.005$ & $0.984$\\
	\hline
	José Manuel & $6.00 \cdot 10^{-9} 2^n + 9.3 \cdot 10^{-6}$ & $0.999$\\
	\hline
	Pablo & $6.1 \cdot 10^{-9} 2^n + 1.1 \cdot 10^{-9}$ & $0.998$\\
	\hline
	Iñaki & $0.06 \cdot 2^n -0.03$ & $0.999$\\
	\hline
\end{tabular}}

\newpage
\subsection{Eficiencia híbrida: Comparativa}

Observaremos experimentalmente que si intentamos ajustar los datos de ejecución de los algoritmos con distintas funciones, la que produce un mejor ajuste es la que expresa su eficiencia en el caso medio.

Tomaremos un algoritmo tipo de cada clase de eficiencia y lo intentaremos ajustar mediante distintas curvas.

\vspace{1cm}
\textbf{Algoritmos cuadráticos}

\begin{figure}[H]\includegraphics[width=13cm]{img/cuad_hibrida.pdf} \centering
	\caption{Comparativa Cuadráticos Híbrida}\end{figure}

Como vemos la función cuadrática es la que mejor se ajusta a los datos.

\vspace{1cm}

\textbf{Algoritmos $n \cdot \log(n)$}

Vamos a aproximar los datos del \textit{quicksort} con una función lineal y una logarítmica. Veremos que la aproximación lineal es mejor de lo que de primeras podríamos pensar.


\begin{figure}[H]\includegraphics[width=13cm]{img/log_hibrida.pdf} \centering
	\caption{Comparativa Logarítmica Híbrida}\end{figure}

Esto se debe a que el logaritmo es menor que cualquier raíz, asintóticamente; es por esto que la función $n \log(n)$ se comporta de una manera parecida a una lineal.


\vspace{1cm}

\textbf{Algoritmos Exponenciales}

Ejecutaremos el algoritmo de Hanói y lo compararemos con funciones polinómicas de diverso grado.

\begin{figure}[H]\includegraphics[width=13cm]{img/expo_hibrida2.pdf} \centering
	\caption{Comparativa Exponencial Híbrida}\end{figure}

Como era de esperar, aproximar el crecimiento exponencial mediante funciones polinómicas es inviable. Cabe destacar que no hemos mostrado el ajuste cúbico porque el método de mínimos cuadrados devuelve una aproximación tan nefasta que se dejan de apreciar bien las demás funciones en la gráfica.

\vspace{1cm}

\textbf{Algoritmos Cúbicos}

Por último aproximaremos mediante las funciones que ya hemos tratado los datos resultantes de la ejecución del algoritmo cúbico de Floyd.

\begin{figure}[H]\includegraphics[width=13cm]{img/floyd_hibrida.pdf} \centering
	\caption{Comparativa Floyd Híbrida}\end{figure}

Se ha de notar que no hemos intentado ajustar el algoritmo de Floyd con una función exponencial. Esto se debe a que dicho ajuste es tan poco realista que las constantes se salen del rango de precisión aritmética del programa empleado para su cálculo (gnuplot).


Por último queremos comentar la proximidad de las funciones cuadrática y cúbica, salvo para datos pequeños que ajusta mejor la cúbica; esto se debe a que las constantes difieren mucho y los datos son insuficientes, por tanto, en un pequeño intervalo las funciones pueden llegar a "parecerse".

\newpage
\section{Ejercicio 4}

En el ejercicio 4 nos pedían ver cómo varía la eficiencia empírica según diversos factores. A lo largo de esta memoria hemos visto que el sistema operativo y el ordenador en el que se realizan los cálculos afectan ligeramente al resultado de la eficiencia, pero que asintóticamente se comportan de la misma manera.

En este apartado nos centraremos, por tanto, en el otro factor relevante: la optimización. Vamos a comparar los tiempos de los algoritmos anteriores cuando los compilamos con diferentes niveles de optimización. Acabaremos viendo que, al igual que los otros dos, la optimización puede mejorarnos el tiempo de ejecución, pero no variar la tendencia asintótica de la eficiencia.

También nos adentraremos en un hecho importante sobre la optimización. Si bien uno esperaría que cuanto más alto el nivel de optimización, mejor se comporta el algoritmo, esto no es siempre cierto. Esto es consecuencia de la implementación interna de los distintos niveles de optimización del compilador, en los que no tenemos pensado entrar, pero que ponen de relieve que debemos hacer un contraste de tiempos entre las versiones con optimización cuando estemos creando algún programa que necesite rapidez.

\newpage
\subsection{Optimización de Burbuja}
\input{tablas/Opt_burbuja_tabla}
\begin{figure}[H]\includegraphics[width=13cm]{img/burbuja_optim_g.pdf} \centering
	\caption{Optimización Burbuja}\end{figure}

Tanto en la última fila de la tabla como en la gráfica podemos notar que el primer nivel de optimización nos baja considerablemente el tiempo de ejecución. Como en la mayoría de otros algoritmos, la optimización de nivel 1 se encuentra un poco por encima de las otras dos, que van alternándose. Aun así, podemos apreciar una leve ventaja del nivel 2 frente al 3.

\newpage 
\subsection{Optimización de Selección}
\input{tablas/Opt_seleccion_tabla}
\begin{figure}[H]\includegraphics[width=13cm]{img/seleccion_optim_g.pdf} \centering
	\caption{Optimización Selección}\end{figure}

En este algoritmo podemos apreciar lo que se mencionaba antes: el nivel 3 no es el más rápido siempre. Unas razones de por qué afecta más en unos algoritmos que en otros es la capacidad de la caché junto a la gestión del algoritmo de sus propios datos. En este caso, el algoritmo peor parado es selección, que aplica menos intercambios que inserción, pero que realiza más comparaciones.

\newpage
\subsection{Optimización de Inserción}
\input{tablas/Opt_insercion_tabla}
\begin{figure}[H]\includegraphics[width=13cm]{img/insercion_optim_g.pdf} \centering
	\caption{Optimización Inserción}\end{figure}

De nuevo, notamos que la diferencia entre optimizar y no hacerlo es notable. En este caso, la diferencia entre las tres optimizaciones es prácticamente nula, así que no tiene mucho sentido sacar información de ahí.

\newpage
\subsection{Optimización de Quicksort}
\input{tablas/Opt_quicksort_tabla}
\begin{figure}[H]\includegraphics[width=12cm]{img/quicksort_optim_g.pdf} \centering
	\caption{Optimización Quicksort}\end{figure}

El Quicksort es el algoritmo más rápido de todos los que estamos sacando de relieve, por lo que podemos apreciar un dato importante, observando un momento las tablas. El Quicksort está por debajo de la versión optimizada del Mergesort. Para 25 millones de datos, el Quicksort tarda $4.5$ segundos mientras que el Mergesort con nivel 1 de optimización tarda $3.76$ segundos. Lo arreglamos fácilmente optimizando también el Quicksort, lo cual lo sigue dejando el más rápido de todos, bajando a $2.34$ segundos en nivel 3.
\newpage
\subsection{Optimización de Mergesort}
\input{tablas/Opt_mergesort_tabla}
\begin{figure}[H]\includegraphics[width=13cm]{img/mergesort_optim_g.pdf} \centering
	\caption{Optimización Mergesort}\end{figure}

En el Mergesort podemos notar, como lo hicimos cuando vimos su subida en el apartado 1 de esta memoria, los escalones que forma cuando cambia el tamaño con el que aplica inserción, pero esta vez en los demás niveles de optimización. La diferencia entre los niveles de optimización en este caso es también nula. 
\newpage
\subsection{Optimización de Heapsort}
\input{tablas/Opt_heapsort_tabla}
\begin{figure}[H]\includegraphics[width=12cm]{img/heapsort_optim_g.pdf} \centering
	\caption{Optimización Heapsort}\end{figure}

Llegamos al Heapsort, con el que nos encontramos que, aunque pareciese que el nivel 1 se comportaba de una forma parecida a los otros dos niveles, puede haber casos en los que no nos haga mucha disminución de tiempo, como aquí. Los tiempos del Heapsort normal con respecto al de nivel 1 no cambian tanto como en los anteriores algoritmos que veíamos, mientras que los otros dos niveles ya nos bajan a la mitad del tiempo, como antes. Las causas de esto recaen sobre la implementación interna de los niveles de optimización y, de nuevo, sobre la gestión del algoritmo de sus datos.

\newpage
\subsection{Optimización de Floyd}
\input{tablas/Opt_floyd_tabla}
\begin{figure}[H]\includegraphics[width=13cm]{img/floyd_optim_g.pdf} \centering
	\caption{Optimización Floyd}\end{figure}

En Floyd podemos presenciar cómo de importante puede ser optimizar, puesto que las curvas que realizan las optimizaciones son mucho más suaves que la del original. Si bien la distancia entre ellos para 750 datos es de 2 segundos, las pendientes de las curvas sugieren que esta distancia aumenta considerablemente en pocos datos más.
\newpage
\subsection{Optimización de Fibonacci}
\input{tablas/Opt_fibonacci_tabla}
\begin{figure}[H]\includegraphics[width=11cm]{img/fibonacci_optim_g.pdf} \centering
	\caption{Optimización Fibonacci}\end{figure}

Aquí encontramos un problema para sacar información, puesto que los tiempos de ejecución para 25 datos son muy pequeños en Fibonacci, y en las gráficas no notamos mucho cambio. Sin embargo, si nos ayudamos de las tablas, podremos fijarnos en que el nivel O0 se encuentra cerca de dos veces el nivel O3 en la mayoría de los puntos. Esto sugiere que aunque no lo veamos, la diferencia entre un ejecutable y otro es prácticamente la misma que hemos visto anteriormente, y el original tarda el doble del tiempo en ejecutarse. Por otro lado, el nivel 1 tampoco nos ofrece mucha mejora, como ocurría con el Heapsort.
\newpage
\subsection{Optimización de Hanói}
\input{tablas/Opt_hanoi_tabla}
\begin{figure}[H]\includegraphics[width=12cm]{img/hanoi_optim_g.pdf} \centering
	\caption{Optimización Hanói}\end{figure}

Por último, el algoritmo de Hanói que es el más lento de todos. Al ser exponencial, de nuevo, como en Fibonacci, la gráfica solo nos muestra algo de información en los últimos puntos, antes de dispararse. Pero allí podemos ver que las pendientes de las curvas del original superan a los de las versiones optimizadas, que dibujan una curva mucho más suave. Conforme más avancemos aumentando el tamaño, más pronunciada será la diferencia entre estos ejecutables. Esta vez el nivel 3 es el que más mejora ofrece.

\newpage
\subsection{Conclusión}
Como conclusión podemos decir que es prioritario optimizar si queremos sacar el máximo juego a nuestros algoritmos, pero que debemos comparar los tres niveles de optimización con algún sencillo test como los anteriores, para quedarnos con el nivel que más mejore la gestión del algoritmo.

Por otro lado, si bien una buena optimización puede aligerarnos la carga del algoritmo en tiempo, no podrá deshacerse de su tendencia asintótica. Prueba de ello es que en todos los datos que hemos recogido, las optimizaciones rondaban la mitad del tiempo del original, lo cual no cambia la tendencia en tamaños grandes. Así que, aunque pueden ser muy provechosas, no podemos confiar solo en las optimizaciones al compilar para hacer una verdadera mejora en el tiempo de nuestro algoritmo. 


\end{document}
